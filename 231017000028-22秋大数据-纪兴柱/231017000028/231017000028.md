# 基于transformer的文本摘要实验

## 学员信息

- 姓名：纪兴柱
- 学号：231017000028

## 实验简述

​	命名实体识别 （NER）是NLP里的一项很基础的任务，旨在定位非结构化文本中提到的命名实体并将其分类为预定义的类别，例如人名、组织、位置、医疗代码、时间表达式、数量、货币价值、百分比等。该实验通过NER更好地认识NLP的相关技术与流程。



## 实验环境

操作系统：win10虚拟机
python=3.9
torch=1.10.1 (cpu)
transformers=4.18.0
datasets=2.4.0



## 实验过程

- 分词器

分词器使用预训练的`'distilbert-base-uncased'`。DistilBERT是一种基于BERT（Bidirectional Encoder Representations from Transformers）模型的轻量级版本。它具有较小的模型尺寸和计算资源需求，同时在许多自然语言处理任务上表现良好。

![image-20231215181657920](C:\temp\231017000028\231017000028.assets\image-20231215181657920.png)

![image-20231215181631909](C:\temp\231017000028\231017000028.assets\image-20231215181631909.png)

​	

- 数据集

​	数据集使用了'conll2003' ，该数据集是一个常用的英文命名实体识别（Named Entity Recognition，NER）数据集。
​	在数据处理函数中，首先对每个样本进行分词和标签对齐，然后移除不需要的列，如ID、tokens、pos_tags、chunk_tags和ner_tags。最后返回经过处理后的数据集，用于模型训练或评估。

![image-20231215193141955](C:\temp\231017000028\231017000028.assets\image-20231215193141955.png)

![image-20231215181949668](C:\temp\231017000028\231017000028.assets\image-20231215181949668.png)

- 数据加载器

  ​	通过torch.utils.data.DataLoader创建了一个数据加载器。参数dataset指定了要加载的训练集(dataset['train'])。batch_size设置为8，表示每个批次中有8个样本。collate_fn参数指定了用于处理批次的函数，这里使用了DataCollatorForTokenClassification，它会将批次中的样本整理为模型需要的格式。shuffle=True表示在每个轮次开始时打乱数据顺序，drop_last=True表示如果最后一个批次样本数量不足8个，则丢弃该批次。

  ![image-20231215184231362](C:\temp\231017000028\231017000028.assets\image-20231215184231362.png)

![image-20231215184504246](C:\temp\231017000028\231017000028.assets\image-20231215184504246.png)

- 下游任务模型

  ​	这个类继承自PreTrainedModel，其中config_class属性设置为PretrainedConfig。

  ​	在__init__方法中，首先加载了预训练的DistilBERT模型(distilbert-base-uncased)作为self.pretrained。然后，定义了一个全连接层self.fc，包含一个dropout层和一个线性层，将输入特征维度768映射到输出类别数9。接下来，通过加载预训练模型的参数，将self.fc的权重初始化为预训练模型的分类器权重。最后，定义了交叉熵损失函数self.criterion。

  ​	在forward方法中，首先将输入数据传递给预训练模型，得到最后一层隐藏状态logits。然后，将logits传递给全连接层self.fc进行分类。如果提供了标签labels，计算交叉熵损失。最后，返回一个字典，包含损失和预测的logits。

  ![image-20231215185934986](C:\temp\231017000028\231017000028.assets\image-20231215185934986.png)

- train

  ​	使用AdamW优化器和线性学习率调度器进行模型的参数优化和学习率更新。在每个批次中，将数据移动到设备上，通过模型进行前向传播并计算损失。然后，执行反向传播和梯度裁剪，更新模型参数和学习率。最后，将模型移回CPU。

  ![image-20231215190348490](C:\temp\231017000028\231017000028.assets\image-20231215190348490.png)

  ​	训练过程中会周期性地打印训练信息，包括轮次，损失、准确率和学习率。经过将近两千次的训练，正确率达99.16%。

  ![image-20231215190735498](C:\temp\231017000028\231017000028.assets\image-20231215190735498.png)

## 实验结论

- 测试函数

  ​	测试函数将模型设置为评估模式，并使用测试数据加载器加载数据。在测试循环中，对于每个批次，通过模型进行前向传播并获取预测的标签索引，然后将预测值和标签值添加到列表中。在一定的间隔内打印进度信息，并限制测试批次的数量。最后，将标签和预测值连接起来，并计算预测准确率并打印出来。
  
  ![image-20231215191100019](C:\temp\231017000028\231017000028.assets\image-20231215191100019.png)
  
  ![image-20231215192737724](C:\temp\231017000028\231017000028.assets\image-20231215192737724.png)

- 训练前测试

  ![image-20231215192717157](C:\temp\231017000028\231017000028.assets\image-20231215192717157.png)

- 训练后测试

  ![image-20231215192925300](C:\temp\231017000028\231017000028.assets\image-20231215192925300.png)

## 实验总结

​	在实验过程中遇到很多问题，包括为环境搭建，数据集的下载，以及模型函数参数设置等等。通过解决以上问题对NLP的处理领域和处理逻辑有了初步认识，感谢老师和热心的同学们。