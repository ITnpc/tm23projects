# 殷慧敏（231017000075）作业

  基于大语言模型对给定文章生成内容贴切的摘要的Project


## 一、背景

工作中需要经常性阅读大量文件，并且对信息快速进行响应，由于全文阅读完时间较长，希望通过大模型能够对文件进行分析，生成摘要信息，让用户快速了解整体文件内容，并且通过摘要确定优先阅读重点。


## 二、目标

基于语言大模型，使用包含分析结果的数据进行预训练，然后对测试数据进行分析生成报告。通过自主搭建代码，熟悉了解大语言模型的用法，以及训练等一些基本使用方式。

## 三、技术环境及模型选型

根据老师课上建议，经过对比考虑，选择了ModelScope社区平台，具备个人GPU算力需求资源，同时社区平台上提供了较多的模型库和相关资源，可以进行各种大语言模型的测试。

对于大模型的选择，经过了多次的筛选和测试，主要是考虑到以下几种因素，第一是是要满足我对业务需求的设定主要是生成式AI方面，其次是需要能够支持训练的，或者是有开源训练代码说明的，还有其他方面例如是否支持中文等等。

在ModelScope社区中，在Jupiter尝试了模型库中的若干大语言模型以及几种预训练集。经过试用和比较，最终选择了PALM文本生成模型（nlp_palm2.0_text-generation_chinese-large）。此模型提供了训练代码，可以进行针对性的训练调优。其他的大模型或多或少无法满足前面所说的需求，或者有的训练时需要较大内存，魔塔社区的资源难以满足，无法运行。

## 四、实施步骤

### 1. 总体思路

大约分为以下几个步骤实现：

a. 按照目标和需求搭建整体项目框架；

b. 准备“测试数据”（一份文件或者报告），能够在项目框架上跑通，即生成摘要；

c. 准备“训练数据”（若干报告文本）对大模型进行训练；

d. 再次提供初期“测试数据”，看大模型生成的摘要信息是否有变化，或者往自己预期的方向上前进；

### 2. 搭建项目框架代码

按照PALM文本生成模型的属性以及ModelScope平台的资源情况，引入依赖，以及初始化tokenizer和model。

```python
# 引入模型依赖
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks
from modelscope.outputs import OutputKeys
# 引入训练相关的依赖
import tempfile
import json
from modelscope.msdatasets import MsDataset
from datasets import Dataset
from modelscope.metainfo import Trainers
from modelscope.trainers import build_trainer
```

### 3. 准备数据

#### 3.1 数据内容说明

本项目中用到的数据主要分为两类，我先找取了一份类似工作中的文件，名字叫做《2023政府工作报告（部分）》，作为测试文件，大约字数在1600左右。

另外一类是做为模型训练用的数据，主要是从网上寻找了一些报告，由于时间所限，大概找了四篇分别是《西宁人才统计分析报告》、《党内统计分析报告》、《巴州区委统计分析报告》、《数字政府系统建设方案（部分）》；

#### 3.2 数据处理说明

根据模型数据格式要求，文档需要处理成模型要求统一json格式。因此，测试文件处理后为[测试数据文件](./dataset/test.json ':include')。

训练文档的处理稍微复杂点，不仅要有原始文档（原文src_txt），每篇文档还要有对应的摘要内容（目标内容tgt_txt），考虑到时间等因素关系，采用快捷的方式生成，即相应的摘要内容也可以使用大模型生成。首先在网上寻找了一些公开的工作报告类文章，然后把这些文档通过chatgpt生成了每篇大约300-500字左右的摘要，作为训练集的目标内容。

所有的原始文档和目标内容最后生成相应的分析实例，保存于data.json文件中，作为训练集。[训练数据文件](./dataset/data.json ':include')

### 4. 大模型首次使用

输入测试文档，让大模型生成摘要结果，部分代码如下：

```python
import json
#当前模型为PALM 2.0摘要生成模型-中文-large
model_name = 'damo/nlp_palm2.0_text-generation_chinese-large'
# step1: 首次执行语句
print('step1: 首次执行语句')
with open("test.json", "r") as f:
    input_data = json.load(f)
input = input_data[0]['source']
text_summary = pipeline(Tasks.text_generation, model=model_name)
result = text_summary(input)
# print('输入文本:\n' + input + '\n')
print('文本摘要结果:\n' + result[OutputKeys.TEXT])
```

输出结果为：
>文本摘要结果:
>开启奋斗新征程

使用原生态大模型生成结果不太理想，字数太少，只有一句话，需要对大模型进行微调训练。
  

### 5. 用训练数据集对大模型进行训练

  读取训练数据文件(./dataset/data.json )，再次转化为模型专用训练数据集中，配置相关训练参数后开始执行训练。处于时间和资源考虑，本次训练周期设置为10，预热步数设置为100等。

  相关脚本代码如下：

```python
# step2: 训练数据集
with open("data.json", "r") as f:
    train_data = json.load(f)
# 用自己数据集构造
train_dataset = MsDataset(Dataset.from_dict(train_data))
eval_dataset = MsDataset(Dataset.from_dict(train_data))
max_epochs = 10
num_warmup_steps = 100   #原始值500
def noam_lambda(current_step: int):
    current_step += 1
    return min(current_step**(-0.5),
               current_step * num_warmup_steps**(-1.5))
# 可以在代码修改 configuration 的配置
def cfg_modify_fn(cfg):
    cfg.preprocessor.sequence_length = 128
    cfg.train.lr_scheduler = {
        'type': 'LambdaLR',
        'lr_lambda': noam_lambda,
        'options': {
            'by_epoch': False
        }
    }
    cfg.train.optimizer = {
        "type": "AdamW",
        "lr": 1e-3,
        "options": {}
    }
    cfg.train.max_epochs = max_epochs 
    cfg.train.dataloader = {
        "batch_size_per_gpu": 8,
        "workers_per_gpu": 1
    }
    return cfg
work_dir = tempfile.TemporaryDirectory().name
kwargs = dict(
    model=model_name,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    work_dir=work_dir, #tempfile.TemporaryDirectory().name,
    cfg_modify_fn=cfg_modify_fn)
trainer = build_trainer(
    name=Trainers.text_generation_trainer, default_args=kwargs)
trainer.train()
```

###  6. 再次运行模型

  完成训练后，使用测试数据文件的数据，再次运行获取摘要。

相关代码示例如下：

```python
# step3: 再次执行测试语句
print('step3: 再次执行语句')
text_summary = pipeline(Tasks.text_generation, model=work_dir + "/output")
result = text_summary(input)
print('二次生成文本摘要结果:\n' + result[OutputKeys.TEXT])
```

### 7. 运行结果

执行运行模型后得到的结果如下：

>二次文本摘要结果:
>人民日报社论：向第二个百年奋斗目标进军新征程

对比首次结果：

>文本摘要结果:
>开启奋斗新征程

从结果看，首次进行摘要测试得出的结果和原文相差甚远，且文字内容非常简单，只有类似简单标题，相去甚远。在执行训练后，再次运行测试后，所得摘要结果，概括方向基本正确,内容也比初次多，说明针对大模型的训练是带来了正向的影响。但是总体来说，生成的文本摘要结果都非常简单，和期望的还有很大差距。


## 四、结果和总结

通过本次项目实践，能够初步运用大模型工具，实现一些原本需要人工处理的文本分析和摘要生成工作，对上课讲解的知识有了更深一步的了解。大模型训练，带来的效果还远远不够。可能原因是提供训练的数据样本不够多，另外对训练的周期和预热步数等参数可能需要多次设置调整，因此训练结果还没有达到理想状态，只是体现出训练有正向效果结论。考虑到整体项目的资源和时间关系，暂无法投入更多时间和资源，后期可以在这个基础上，自己再进一步拓展训练数据集，或者调整训练参数，看看是否有更好的效果。

通过本次学习，也非常希望可以将学习到的知识，深入运用到工作中去，用大模型技术在工作中创造更大的价值。

