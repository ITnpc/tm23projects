# 古诗句生成 
# The Generation of Ancient Poetry Sentences
## 作者: 戴日正
## 班级：23年计算机春季班
## 学号：231017000143
## 功能简述：通过给出的关键字生成相关的古诗句


# Code introduction, divided into the following parts
## 代码说明

* dataset/poetry_trains.txt：数据集,此数据集使用'#'作为分割词

* scripts/MyNet：模型类

* scripts/MyDataset：数据集调用类

* scripts/model.pkl：模型文件

* scripts/middle_text：训练监测值

* scripts/train.py：训练模型

* scripts/test.py：测试模型


## 代码概述

* 模型类概述：

模型类定义了一个名为 `MyNet` 的神经网络模型，它继承自 PyTorch 的 `nn.Module` 类。
该模型包含几个主要的组成部分：

1. `__init__` 方法定义了模型的基本参数和结构。其中，`vocab_size` 表示词汇表的大小，`embeding` 是词嵌入的维度，`hiddens` 是隐藏层的维度，`lstm_layers` 是 LSTM 层的层数。模型中包含一个嵌入层（`self.embedding`），一个 LSTM 层（`self.lstm`），以及两个全连接层（`self.h2h` 和 `self.h2o`）。
2. `forward` 方法定义了模型的前向传播过程。输入为单词 ID 的批量（`word_ids`），以及可选的 LSTM 隐藏状态（`lstm_hidden`）。首先，该方法将单词 ID 转换为对应的词嵌入，然后将嵌入数据输入 LSTM 层。LSTM 层的输出被送入第一个全连接层（`self.h2h`），然后进入第二个全连接层（`self.h2o`），产生最终的输出


* 数据集调用类概述：

数据集调用类定义了一个名为 `MyDataset` 的自定义 PyTorch 数据集类。该数据集类用于处理和操作序列数据，例如文本文件中的单词序列。
该模型包含几个主要的组成部分：

1. `__init__` 方法: 初始化数据集对象。它接受两个参数，`seqs`（序列长度）和 `file`（文本文件的路径）。方法内部还定义了 `<SOS>` 和 `<EOS>` 的整数编码。
   它读取文本文件，将每一行的单词转换为整数编码，并存储在 `indices` 列表中。同时，它构建了一个从单词到索引的映射字典 `word2index` 和从索引到单词的映射字典 `index2word`。最后，将 `indices` 转换为 NumPy 数组，并存储在 `self.data` 中。
2. `__len__` 方法: 返回数据集的长度，即数据集中的样本数量。计算方式为 `(len(self.data) - 1) // self.seqs`，这里的 `-1` 是因为数据集中每个样本之间有一个 `<EOS>` 分隔符。
3. `__getitem__` 方法: 根据索引 `i` 返回一个样本。该方法将索引 `i` 对应的位置范围内的数据（长度为 `self.seqs`）作为输入张量，将下一位置的数据作为输出张量。这两个张量都通过 `torch.as_tensor()` 方法进行了转换。


##  导入库

* `numpy`: 用于进行高效的数值计算
* `torch`: PyTorch 库，提供张量和神经网络功能
* `torch.utils.data`: 提供数据集类，简化数据加载和预处理


## 操作

* 可使用已训练的模型直接测试或重新生成训练模型

* 训练：python train.py

* 测试：python test.py


