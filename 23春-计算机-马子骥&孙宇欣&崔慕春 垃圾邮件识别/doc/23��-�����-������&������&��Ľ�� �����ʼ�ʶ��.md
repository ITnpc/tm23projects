# 23春 文本挖掘项目



## 团队成员

该项目由以下成员分工完成：

马子骥 231017000155 ： 传统方法文本挖掘（TFIDF，随机森林，支持向量机）及数据验证，所有方法评估总结及文档编写

孙宇欣 231017000150：CNN神经网络文本挖掘及数据验证，方法评估

崔慕春 231017000151：RNN神经网络文本挖掘及数据验证，方法评估



## 项目背景

该项目为邮件内容内容的垃圾邮件识别，数据集来源于网络，方法均来源于开源方法。使用方法包括sklearn包所包含的tfidf词频统计和向量化方法，随机森林分类方法，支持向量机。神经网络方法使用CNN和RNN，并且完成模型的评估



## 传统方法

使用pandas处理数据，使用matplotlib进行绘图，读取本地数据集

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('../datasets/spam.tsv', sep='\t')

# Data browsing
df.describe()
```

可视化探索性分析

```python
# Text length analysis
plt.hist(data[data['label'] == 'ham']['length'], bins = 100, alpha = 0.7)
plt.hist(data[data['label'] == 'spam']['length'], bins = 100, alpha = 0.7)
plt.show()

# Text label analysis
plt.hist(data[data['label'] == 'ham']['punct'], bins = 100, alpha = 0.7)
plt.hist(data[data['label'] == 'spam']['punct'], bins = 100, alpha = 0.7)
plt.show()
```

训练集、测试集准备，文本数据作为输入，标签作为输出

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test =  train_test_split(data['message'], data['label'], test_size = 0.3, random_state =0, shuffle = True)
```

随机森林建模、预测

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier

from sklearn.pipeline import Pipeline

# tokenization
classifier = Pipeline([("tfidf", TfidfVectorizer()) , ("classifier", RandomForestClassifier(n_estimators=100))])

# fit classifier
classifier.fit(X_train, y_train)

# predict
y_pred = classifier.predict(X_test)

# metrics
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

accuracy_score(y_test, y_pred)

confusion_matrix(y_test, y_pred)
```

支持向量机建模、预测

```python
from sklearn.svm import SVC

# model pipeline
svm = Pipeline([("tfidf", TfidfVectorizer()) , ("classifier", SVC(C = 100, gamma='auto'))])

# train model
svm.fit(X_train, y_train)

# predict
y_pred = svm.predict(X_test)

# metrics
accuracy_score(y_test, y_pred)

confusion_matrix(y_test, y_pred)
```

测试模型效果

```python
test1 = ['Hello, You are learning natural Language Processing']
test2 = ['Hope you are doing good and learning new things !']
test3 = ['Congratulations, You won a lottery ticket worth $1 Million ! To claim call on 446677'] # spam

# random forest
print(classifier.predict(test1))
print(classifier.predict(test2))
print(classifier.predict(test3))

# svm
print(svm.predict(test1))
print(svm.predict(test2))
print(svm.predict(test3))
```



## 神经网络方法准备

引入tensorflow必要库

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D
from tensorflow.keras.layers import LSTM, Embedding
from tensorflow.keras.models import Model
```

读取数据数据，清洗

```python
# load data
df = pd.read_csv('../datasets/spam.csv', encoding='ISO-8859-1')
df = df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)

# new label for dataset
df.columns = ['labels', 'data']
df['b_labels'] = df['labels'].map({'ham':0, 'spam':1}) # binary label

```

训练集测试集拆分，数据转换

```python
# split the data
x_train, x_test, y_train, y_test = train_test_split(df['data'], y, test_size = 0.33)

# convert sentences into sequences
max_vocab_size = 20000
tokenizer = Tokenizer(num_words=max_vocab_size)

# fit on tokenizer
tokenizer.fit_on_texts(x_train)
sequence_train = tokenizer.texts_to_sequences(x_train)
sequence_test = tokenizer.texts_to_sequences(x_test)

# check word index mapping (to check the number of words in vocabulary)
word2idx = tokenizer.word_index
V = len(word2idx)

# pad sequences
data_train = pad_sequences(sequence_train)

# set the value of T to get sequence length
T = data_train.shape[1]

# pad the test set
data_test = pad_sequences(sequence_test, maxlen=T)
```



## CNN网络及方法评估

建立模型

```python
# create the model

# choose the embedding dimensionality
D = 20 # hyper parameter

# Input layer
i = Input(shape=(T,)) # input layer take input shape of T

# Embedding layer
x = Embedding(V + 1, D)(i) # take integers and return sequences and vectors

# Fisrt CNN layer
x = Conv1D(32, 3, activation='relu')(x)
x = MaxPooling1D(3)(x)

# second CNN layer
x = Conv1D(64, 3, activation = 'relu')(x)
x = MaxPooling1D(3)(x)

# third CNN layer
x = Conv1D(128, 3, activation = 'relu')(x)
x = GlobalMaxPooling1D()(x)

# Dense layer
x = Dense(1, activation='sigmoid')(x)

model = Model(i, x)
```

模型编译、训练

```python
# compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# train model
r = model.fit(x=data_train, y = y_train, epochs=5, validation_data=(data_test, y_test))
```



## RNN网络及方法评估

建立模型

```python
# build model

# choose embedding dimensionality
D = 20 # hyper parameter

# hidden state vectorsize
M = 15

# inputlayer
i = Input(shape=(T,)) # input layer input shape of T

# embedding layer
x = Embedding(V + 1, D)(i)

# LSTM layer
x=  LSTM(M, return_sequences=True)(x)
x = GlobalMaxPooling1D()(x)

# Dense layer
x = Dense(1, activation='sigmoid')(x)

model = Model(i, x)
```

模型编译、训练

```python
# compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


# train the mode
r = model.fit(x=data_train, y=y_train, epochs=10, validation_data=(data_test, y_test))
```





## 神经网络训练效果评估

Loss函数

```python
# plot loss function
import matplotlib.pyplot as plt
plt.plot(r.history['loss'], label='Loss')
plt.plot(r.history['val_loss'], label='Validation Loss')
plt.legend()
plt.show()
```

准确率

```python
# plot accuracy
plt.plot(r.history['accuracy'], label='Accuracy')
plt.plot(r.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.show()
```

