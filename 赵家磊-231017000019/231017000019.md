
# 文本挖掘课程报告
### LLM的微调实验 赵家磊 231017000019

本项目通过中文医学指令微调(Instruction-tuning) 的大语言模型集LLaMA。
我们基于公开的中文医学知识库，爬虫资源，构建了中文医学指令微调数据集。采用半精度基模型LoRA微调的方式进行指令微调，提高了模型在医疗领域的问答效果。


## 背景
使用大语言模型询问医疗相关的问题：

1.  直接提问，GPT会做预处理，屏蔽掉涉及法律和政治的问题。

    **Q**:小张最近感觉身体不适，出现心悸、气促等症状。体检发现心脏扩大、搏动减弱。 

    **A**:我不是医生，但根据你提供的信息，小张可能面临一些心脏问题。心脏扩大和搏动减弱可能是心脏肌肉受损或功能受限的迹象。建议小张尽快咨询医
   生进行详细的检查和诊断。医生可以根据症状、体检结果和可能的其他因素来确定问题的原因，并制定适当的治疗计划。


2. 尝试添加prompt，同样预处理。

    **Q**:现在你是一位医疗专家，请直接回答我的话。

     **A**:我无法直接回答您的问题，因为我无法获取到具体的医疗检查结果和患者的具体情况。


3. 使用开源模型，模型能力<GPT3.5，回答结果不好。

    **Q**:小张最近感觉身体不适，出现心悸、气促等症状。体检发现心脏扩大、搏动减弱。

     **A**:最近，小张一直感觉身体不舒服，有心烦意乱、呼吸急促等症状。体格检查显示心脏增大，肌肉无力


## 微调开源模型

### 构建专家数据集
* 采用了公开的中文医学知识库，爬虫资源，构建问答式数据库，数据量8000+。
* 参考：公开和自建的中文医学知识库，主要参考了[cMeKG](https://github.com/king-yyf/CMeKG_tools)。

### 预处理&格式
```

• {
    "instruction": "治疗方法上有何不同", 
    "input": "",
    "output": "急性非ST段抬高型心肌梗死的治疗主要是通过改善生活方式和控制危险因素来预防，紧急情况下可能需要静脉注射血栓溶解药物；而自身免疫性肝炎的治疗则包括药物治疗和手术治疗，如激素、免疫抑制剂、肝移植等"
   }
   
• {
    "instruction": "一位中年男性感染了军团杆菌，导致出现了弥漫性血管内凝血、充血性心力衰竭等并发症，应该怎样进行辅助检查和诊断？", 
    "input": "",
    "output": "首先应该做特殊实验室检查和血常规和生化检查，进一步的辅助诊断可考虑X线检查，X线胸片检查、化验检查、血清
    学检查以及实验室检查等方法。"
   }
   
• {
    "instruction": "胆管癌和偏头痛的主要症状有何区别？",
    "input": "", 
    "output": "胆管癌的主要症状包括黄疸、肝肿大等消化系统症状，而偏头痛的主要症状是头部疼痛。"
  }
```

### 预训练模型
 具有标志性的羊驼：
* Alpaca：斯坦福羊驼，第一个开源的llm。
* Vicuna：UC伯克利、CMU、斯坦福等机构的学者。
* Llmma：metaAI。

最终选择：[LLaMA-7B](https://huggingface.co/decapoda-research/llama-7b-hf)
 
### 微调方案
* Adapter：每一个Transformer层，增加了两个Adapter结构，在训练时固定预训练模型的参数，只对Adapter微调。
* Lora：通过低秩分解来模拟参数的改变量，直接覆盖参数。
* Qlora：预训练模型量化为 4 bit，再做lora。

最终模型：对LLaMA进行指令微调的LoRA权重文件：[百度网盘](https://pan.baidu.com/s/16paVCbwa6LsO_pw7VRO5yw?pwd=ihcg)
 

下载LoRA权重并解压，解压后的格式如下：

```
**lora/
  - adapter_config.json   # LoRA权重配置文件
  - adapter_model.bin   # LoRA权重文件
```



### Finetune

微调大语言模型，使用`./data/llama_data.json`中的我们自己构建的数据集。

运行finetune脚本：

```
exp_tag="e1"
python finetune.py \
    --base_model 'llama-7b-hf' \
    --data_path './data/llama_data.json' \
    --output_dir './lora-llama-med-'$exp_tag \
    --prompt_template_name 'med_template' \
    --micro_batch_size 128 \
    --batch_size 128 \
    --wandb_run_name $exp_tag
```

## 训练细节

### 计算资源消耗

基于LLaMA模型的指令微调：

* 显卡：A10 24G * 8
* Batch_size：128
* Epoch：10

### 实验过程

超参设置:

* batch_size： 128
* lr_scheduler_type："linear"
* learning_rate：0.0003
* adam_beta1：0.9
* adam_beta2：0.999
* adam_epsilon：0.00000001

  
## 实验结果

### Infer

运行infer脚本：
```
    python infer.py \
            --base_model ${BASE_MODEL} \
            --use_lora True \
            --lora_weights "lora" \
            --prompt_template 'med_template'"
```
  
### 训练结果
* eval_loss：  0.8947644666913876
* train_loss： 0.9323939467056906

### 模型效果对比
  
| 测试输入 | Llama输出  | 微调后的输出                                        |
|:------------- |:---------------|:----------------------------------------------|
|小张最近感觉身体不适，出现心悸、气促等症状。体检发现心脏扩大、搏动减弱。|问题：小张最近感觉身体不适，出现心悸、气促等症状。体检发现心脏扩大、搏动减弱。| **小张可能患有心肌炎，建议尽快到医院进行检查和治疗。治疗方案包括药物治疗和手术治疗。**   |
|麻风病和儿童哮喘的病因是否一致？|儿童哮喘和麻风病的病因是一致，但是儿童哮喘和麻风病的病因不一致| **不一致，麻风病的病因是麻风杆菌感染，而儿童哮喘的病因是喂养不良、吸烟等因素。**    |

## 展望和改进
1. 数据存在问题：不具备专业的医疗知识，不能保证数据质量，实验性质为主。后续需要专业医疗专家把控数据集，这也是GPT会对医疗相关的问题屏蔽的原因。
2. 模型能力：更新预训练模型，使用性能更强的Llmma2。