{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Visualizing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()   # To clear the defined variables and operations of the previous cell\n",
    "# create graph\n",
    "a = tf.constant(2, name=\"a\")\n",
    "b = tf.constant(3, name=\"b\")\n",
    "c = tf.add(a, b, name=\"addition\")\n",
    "# creating the writer out of the session\n",
    "# writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "# launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # or creating the writer inside the session\n",
    "    writer = tf.summary.FileWriter('logs/', sess.graph)\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Writing Summaries to Visualize Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. tf.summary.scalar:\n",
    "Randomly pick 100 values from a standard Normal distribution, N(0, 1), and plot them one after the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "Done with writing the scalar summary\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()   # To clear the defined variables and operations of the previous cell\n",
    "# create the scalar variable\n",
    "x_scalar = tf.get_variable('x_scalar', shape=[], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
    "print(x_scalar.shape)\n",
    "# ____step 1:____ create the scalar summary\n",
    "first_summary = tf.summary.scalar(name='My_first_scalar_summary', tensor=x_scalar)\n",
    "init = tf.global_variables_initializer()\n",
    "# launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # ____step 2:____ creating the writer inside the session\n",
    "    writer = tf.summary.FileWriter('logs/', sess.graph)\n",
    "    for step in range(100):\n",
    "        # loop over several initializations of the variable\n",
    "        sess.run(init)\n",
    "        # ____step 3:____ evaluate the scalar summary\n",
    "        summary = sess.run(first_summary)\n",
    "        # ____step 4:____ add the summary to the writer (i.e. to the event file)\n",
    "        writer.add_summary(summary, step)\n",
    "    print('Done with writing the scalar summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. tf.summary.histogram:\n",
    "Continue the previous example by adding a matrix of size 30x40, whose entries come from a standard normal distribution. Initialize this matrix 100 times and plot the distribution of its entries over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing the summaries\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()   # To clear the defined variables and operations of the previous cell\n",
    "# create the variables\n",
    "x_scalar = tf.get_variable('x_scalar', shape=[], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
    "x_matrix = tf.get_variable('x_matrix', shape=[30, 40], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
    "# ____step 1:____ create the summaries\n",
    "# A scalar summary for the scalar tensor\n",
    "scalar_summary = tf.summary.scalar('My_scalar_summary', x_scalar)\n",
    "# A histogram summary for the non-scalar (i.e. 2D or matrix) tensor\n",
    "histogram_summary = tf.summary.histogram('My_histogram_summary', x_matrix)\n",
    "init = tf.global_variables_initializer()\n",
    "# launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # ____step 2:____ creating the writer inside the session\n",
    "    writer = tf.summary.FileWriter('logs/', sess.graph)\n",
    "    for step in range(100):\n",
    "        # loop over several initializations of the variable\n",
    "        sess.run(init)\n",
    "        # ____step 3:____ evaluate the merged summaries\n",
    "        summary1, summary2 = sess.run([scalar_summary, histogram_summary])\n",
    "        # s____step 4:____ add the summary to the writer (i.e. to the event file) to write on the disc\n",
    "        writer.add_summary(summary1, step)\n",
    "        # repeat steps 4 for the histogram summary\n",
    "        writer.add_summary(summary2, step)\n",
    "    print('Done writing the summaries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  tf.summary.merge_all() \n",
    "As mentioned in the code, we need to run every summary (e.g. sess.run([scalar_summary, histogram_summary])) and then use our writer to write each of them to the disk. In practice, we can use any number of summaries to track different parameters in our model. This makes running and writing the summaries extremly inefficient. The way around it is to merge all summaries in our graph and run them at once inside your session. This can be done with tf.summary.merge_all() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. tf.summary.image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()   # To clear the defined variables and operations of the previous cell\n",
    "# create the variables\n",
    "w_gs = tf.get_variable('W_Grayscale', shape=[30, 10], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
    "w_c = tf.get_variable('W_Color', shape=[50, 30], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
    "# ___step 0:___ reshape it to 4D-tensors\n",
    "w_gs_reshaped = tf.reshape(w_gs, (3, 10, 10, 1))\n",
    "w_c_reshaped = tf.reshape(w_c, (5, 10, 10, 3))\n",
    "# ____step 1:____ create the summaries\n",
    "gs_summary = tf.summary.image('Grayscale', w_gs_reshaped)\n",
    "c_summary = tf.summary.image('Color', w_c_reshaped, max_outputs=5)\n",
    "# ____step 2:____ merge all summaries\n",
    "merged = tf.summary.merge_all()\n",
    "# create the op for initializing all variables\n",
    "init = tf.global_variables_initializer()\n",
    "# launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # ____step 3:____ creating the writer inside the session\n",
    "    writer = tf.summary.FileWriter('logs/', sess.graph)\n",
    "    # initialize all variables\n",
    "    sess.run(init)\n",
    "    # ____step 4:____ evaluate the merged op to get the summaries\n",
    "    summary = sess.run(merged)\n",
    "    # ____step 5:____ add summary to the writer (i.e. to the event file) to write on the disc\n",
    "    writer.add_summary(summary)\n",
    "    print('Done writing the summaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://itnext.io/how-to-use-tensorboard-5d82f8654496"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
