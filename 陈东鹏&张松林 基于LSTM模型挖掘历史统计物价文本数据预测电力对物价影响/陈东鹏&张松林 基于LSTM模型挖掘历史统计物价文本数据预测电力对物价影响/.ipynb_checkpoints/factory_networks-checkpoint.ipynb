{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(lstm_neurons=32, hidden_layers=2, lenth=30, dims=1, n_out=3):\n",
    "    model = Sequential()\n",
    "    for i in range(hidden_layers - 1):\n",
    "        model.add(LSTM(lstm_neurons, return_sequences=True, input_shape=(lenth, dims)))\n",
    "        model.add(BatchNormalization()) #like dropout\n",
    "    model.add(LSTM(lstm_neurons, return_sequences=False)) \n",
    "    model.add(Dense(n_out))\n",
    "    network_structure = \"lstm_M\" + str(lstm_neurons) + \"_\" + str(hidden_layers)\n",
    "    return network_structure, model\n",
    "\n",
    "# s, model = create_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mutiple_model(trainX, trainY, testX, testY, lenth=30, dims=1):\n",
    "    # 打开一个文件\n",
    "    fo = open(\"experiments/lstm_univariate.txt\", \"w+\")\n",
    "    array_lstm_neurons = [16, 32, 64, 128]\n",
    "    array_hidden_layers = [1, 2, 3, 4]\n",
    "    # array_lstm_neurons = [16]\n",
    "    # array_hidden_layers = [1, 2]\n",
    "    \n",
    "    for i in range(len(array_lstm_neurons)):\n",
    "        for j in range(len(array_hidden_layers)):\n",
    "            print(array_lstm_neurons[i], \",\", array_hidden_layers[j])\n",
    "            \n",
    "            # create and fit the LSTM network\n",
    "            network_structure, model = create_model(array_lstm_neurons[i], array_hidden_layers[j], lenth, dims)\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "            history = model.fit(trainX, trainY, epochs=50, batch_size=30, validation_split=0.25, verbose=0) #verbose：debug信息\n",
    "            # epochs=30, nearly converge\n",
    "             \n",
    "            # make predictions\n",
    "            trainPredict = model.predict(trainX)\n",
    "            testPredict = model.predict(testX)\n",
    "            # invert predictions\n",
    "            trainPredict = scaler.inverse_transform(trainPredict)\n",
    "            trainYInverse = scaler.inverse_transform([trainY])\n",
    "            testPredict = scaler.inverse_transform(testPredict)\n",
    "            testYInverse = scaler.inverse_transform([testY])\n",
    "            \n",
    "            # Plot training & validation loss values\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.plot(history.history['val_loss'])\n",
    "            plt.title('Model loss')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Test'], loc='upper left')\n",
    "            plt.savefig('experiments/loss_' + network_structure + '.png')\n",
    "            \n",
    "            fo.write('\\n\\n------------' + network_structure + \"------------\\n\")\n",
    "            # calculate mean absolute error\n",
    "            trainScoreMAE = mean_absolute_error(trainYInverse[0], trainPredict[:,0])\n",
    "            testScoreMAE = mean_absolute_error(testYInverse[0], testPredict[:,0])\n",
    "            fo.write('\\nTrain Score: %.2f MAE' % (trainScoreMAE))\n",
    "            fo.write('\\nTest Score: %.2f MAE' % (testScoreMAE))\n",
    "            # calculate root mean squared error\n",
    "            trainScoreRMSE = math.sqrt(mean_squared_error(trainYInverse[0], trainPredict[:,0]))\n",
    "            testScoreRMSE = math.sqrt(mean_squared_error(testYInverse[0], testPredict[:,0]))\n",
    "            fo.write('\\nTrain Score: %.2f RMSE' % (trainScoreRMSE))\n",
    "            fo.write('\\nTest Score: %.2f RMSE' % (testScoreRMSE))\n",
    "            # calculate R square\n",
    "            trainScoreR = r2_score(trainYInverse[0], trainPredict[:,0])\n",
    "            testScoreR = r2_score(testYInverse[0], testPredict[:,0])\n",
    "            fo.write('\\nTrain Score: %.2f R square' % (trainScoreR))\n",
    "            fo.write('\\nTest Score: %.2f R square ' % (testScoreR))\n",
    "            \n",
    "            keras.backend.clear_session()\n",
    "            \n",
    "    # 关闭打开的文件\n",
    "    fo.close()\n",
    "    return\n",
    "    \n",
    "# mutiple experiments\n",
    "# lenth = time_steps\n",
    "# dims = look_back//time_steps\n",
    "# print(\"lenth: %d, dims: %d\" % (lenth, dims))\n",
    "# run_mutiple_model(trainX, trainY, testX, testY, lenth, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
