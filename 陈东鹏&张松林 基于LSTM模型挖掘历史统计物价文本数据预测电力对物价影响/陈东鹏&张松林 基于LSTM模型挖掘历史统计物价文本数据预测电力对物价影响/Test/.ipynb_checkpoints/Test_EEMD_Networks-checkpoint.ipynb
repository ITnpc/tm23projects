{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import pylab as plt  # matplotlib的一个子包\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error # 平方绝对误差\n",
    "from sklearn.metrics import r2_score  # R square\n",
    "\n",
    "import sys \n",
    "sys.path.append(r'C:\\\\Users\\\\demo\\\\workplace\\\\Time-Series-Prediction-with-LSTM\\\\')  # 要用绝对路径\n",
    "from utils import eemd_tools, data_tools, networks_factory, data_metrics\n",
    "from utils.constants import const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# shape (1901, 4)\n"
     ]
    }
   ],
   "source": [
    "data_multi = np.load(const.PROJECT_DIR + \"data/eemd/apple/data_multi.npy\")\n",
    "print(\"# shape\", data_multi.shape)  # not .shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# shape: (1888, 53)\n",
      "True\n",
      "1510 378\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# normalize features\n",
    "scaler = data_tools.Ne_MinMaxScaler\n",
    "scaled = scaler.fit_transform(data_multi)\n",
    "\n",
    "output = 1\n",
    "lag = 13\n",
    "\n",
    "reframed = data_tools.series_to_supervised(scaled, lag, output)\n",
    "# drop columns we don't want to predict\n",
    "index_drop = [-j-1 for j in range(data_multi.shape[1] - 1)]\n",
    "reframed.drop(reframed.columns[index_drop], axis=1, inplace=True)\n",
    "data_supervised = reframed.values\n",
    "print(\"# shape:\", reframed.shape)\n",
    "print(len(data_multi) == len(reframed) + lag)\n",
    "# print(reframed.head(3))\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(data_supervised) * const.TRAIN_SCALE)\n",
    "test_size = len(data_supervised) - train_size\n",
    "train_data, test_data = data_supervised[0:train_size,:], data_supervised[train_size:len(data_multi),:]\n",
    "print(len(train_data), len(test_data))\n",
    "print(len(data_supervised) == len(train_data) + len(test_data)) \n",
    "# print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# shape: (1510, 52)\n",
      "# shape: (378, 52)\n"
     ]
    }
   ],
   "source": [
    "# split into input and outputs\n",
    "train_X, train_Y = train_data[:, :-1], train_data[:, -1]\n",
    "test_X, test_Y = test_data[:, :-1], test_data[:, -1]\n",
    "print(\"# shape:\", train_X.shape)\n",
    "print(\"# shape:\", test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = networks_factory.EPOCHS\n",
    "n_batch_size = networks_factory.BATCH_SIZE\n",
    "n_hidden_neurons = networks_factory.HIDDEN_NEURONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BP: validation_data=(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------neural_nets_flag: BP--------------\n",
      "Epoch 00471: early stopping\n",
      "# Finished Training...\n"
     ]
    }
   ],
   "source": [
    "n_dims = train_X.shape[1]  # magic number !\n",
    "# create model\n",
    "s, model = networks_factory.create_bp_model(hidden_neurons=n_hidden_neurons, dims=n_dims, n_out=1)\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')  # notice: Classification problem and regression problem\n",
    "# Fit the model\n",
    "print(\"-----------neural_nets_flag: BP--------------\")\n",
    "history = model.fit(train_X, train_Y, epochs=n_epoch, batch_size=n_batch_size, validation_data=(test_X, test_Y), \n",
    "                    verbose=0, callbacks=[networks_factory.ES]) \n",
    "print(\"# Finished Training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.5605, Test RMSE: 0.2246\n",
      "Train MAPE: 0.0315, Test MAPE: 0.0194\n",
      "Train Dstat: 0.7270, Test Dstat: 0.7772\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "train_predict = model.predict(train_X)\n",
    "test_predict = model.predict(test_X)\n",
    "\n",
    "time_steps = lag  # for the same uniform interface of inv_transform_multi()\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "temp_train_X = train_X.reshape((train_X.shape[0], time_steps, train_X.shape[1]//time_steps))\n",
    "temp_test_X = test_X.reshape((test_X.shape[0], time_steps, test_X.shape[1]//time_steps))\n",
    "\n",
    "# invert predictions\n",
    "inv_trainP, inv_trainY = data_tools.inv_transform_multi(scaler, temp_train_X, train_predict, train_Y)\n",
    "inv_testP, inv_testY = data_tools.inv_transform_multi(scaler, temp_test_X, test_predict, test_Y)\n",
    "\n",
    "# calculate RMSE, MAPE, Dstat\n",
    "train_rmse = sqrt(mean_squared_error(inv_trainP, inv_trainY))\n",
    "test_rmse = sqrt(mean_squared_error(inv_testP, inv_testY))\n",
    "print('Train RMSE: %.4f, Test RMSE: %.4f' % (train_rmse, test_rmse))\n",
    "train_mape = data_metrics.MAPE(inv_trainP, inv_trainY)\n",
    "test_mape = data_metrics.MAPE(inv_testP, inv_testY)\n",
    "print('Train MAPE: %.4f, Test MAPE: %.4f' % (train_mape, test_mape))\n",
    "train_ds = data_metrics.Dstat(inv_trainP, inv_trainY)\n",
    "test_ds = data_metrics.Dstat(inv_testP, inv_testY)\n",
    "print('Train Dstat: %.4f, Test Dstat: %.4f' % (train_ds, test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM, RNN: validation_data=(temp_test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1510, 13, 4) (1510,)\n",
      "(378, 13, 4) (378,)\n"
     ]
    }
   ],
   "source": [
    "time_steps = lag\n",
    "n_dims = 4  # magic number !\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], time_steps, train_X.shape[1]//time_steps))\n",
    "test_X = test_X.reshape((test_X.shape[0], time_steps, test_X.shape[1]//time_steps))\n",
    "print(train_X.shape, train_Y.shape)\n",
    "print(test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------neural_nets_flag: RNN--------------\n",
      "Epoch 00247: early stopping\n",
      "# Finished Training...\n",
      "Train RMSE: 0.3255, Test RMSE: 0.3596\n",
      "Train MAPE: 0.0222, Test MAPE: 0.0338\n",
      "Train Dstat: 0.7641, Test Dstat: 0.6711\n",
      "-----------neural_nets_flag: LSTM--------------\n"
     ]
    }
   ],
   "source": [
    "neural_nets_flags = [const.FLAG_NN_RNN, const.FLAG_NN_LSTM]\n",
    "\n",
    "for i, neural_nets_flag in enumerate(neural_nets_flags):\n",
    "    print(\"-----------neural_nets_flag: %s--------------\" % const.FLAG_NN_STRING[neural_nets_flag])\n",
    "    if (neural_nets_flag == const.FLAG_NN_RNN):\n",
    "        # --- RNN MODEL --- #\n",
    "        s, model = networks_factory.create_rnn_model(hidden_neurons=32, lenth=time_steps, dims=n_dims, n_out=1)\n",
    "    elif (neural_nets_flag == const.FLAG_NN_LSTM):\n",
    "        # --- LSTM MODEL --- #\n",
    "        s, model = networks_factory.create_lstm_model(lstm_neurons=32, hidden_layers=2, lenth=time_steps, dims=n_dims, n_out=1)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    history = model.fit(train_X, train_Y, epochs=n_epoch, batch_size=n_batch_size, validation_data=(test_X, test_Y), \n",
    "                    verbose=0, callbacks=[networks_factory.ES]) \n",
    "    print(\"# Finished Training...\")\n",
    "    # make a prediction\n",
    "    train_predict = model.predict(train_X) \n",
    "    test_predict = model.predict(test_X)\n",
    "                                                    \n",
    "    # invert predictions\n",
    "    inv_trainP, inv_trainY = data_tools.inv_transform_multi(scaler, train_X, train_predict, train_Y)\n",
    "    inv_testP, inv_testY = data_tools.inv_transform_multi(scaler, test_X, test_predict, test_Y)\n",
    "\n",
    "    # calculate RMSE, MAPE, Dstat\n",
    "    train_rmse = sqrt(mean_squared_error(inv_trainP, inv_trainY))\n",
    "    test_rmse = sqrt(mean_squared_error(inv_testP, inv_testY))\n",
    "    print('Train RMSE: %.4f, Test RMSE: %.4f' % (train_rmse, test_rmse))\n",
    "    train_mape = data_metrics.MAPE(inv_trainP, inv_trainY)\n",
    "    test_mape = data_metrics.MAPE(inv_testP, inv_testY)\n",
    "    print('Train MAPE: %.4f, Test MAPE: %.4f' % (train_mape, test_mape))\n",
    "    train_ds = data_metrics.Dstat(inv_trainP, inv_trainY)\n",
    "    test_ds = data_metrics.Dstat(inv_testP, inv_testY)\n",
    "    print('Train Dstat: %.4f, Test Dstat: %.4f' % (train_ds, test_ds))\n",
    "\n",
    "print(\"# All Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot and save model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
