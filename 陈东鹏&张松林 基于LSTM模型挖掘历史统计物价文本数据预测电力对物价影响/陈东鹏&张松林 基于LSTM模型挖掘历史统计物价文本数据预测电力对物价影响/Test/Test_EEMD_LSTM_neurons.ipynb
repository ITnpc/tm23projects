{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import pylab as plt  # matplotlib的一个子包\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error # 平方绝对误差\n",
    "from sklearn.metrics import r2_score  # R square\n",
    "\n",
    "import sys \n",
    "sys.path.append(r'C:\\\\Users\\\\demo\\\\workplace\\\\Time-Series-Prediction-with-LSTM\\\\')  # 要用绝对路径\n",
    "from utils import eemd_tools, data_tools, networks_factory, data_metrics\n",
    "from utils.constants import const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# shape (1901, 4)\n",
      "# dims:  4\n"
     ]
    }
   ],
   "source": [
    "data_multi = np.load(const.PROJECT_DIR + \"data/eemd/apple/data_multi.npy\")\n",
    "print(\"# shape\", data_multi.shape)  # not .shape()\n",
    "# print(data_multi)\n",
    "n_dims = data_multi.shape[1]  # magic number !\n",
    "print(\"# dims: \", n_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# shape: (1871, 121)\n",
      "True\n",
      "1496 375\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# normalize features\n",
    "scaler = data_tools.Po_MinMaxScaler\n",
    "scaled = scaler.fit_transform(data_multi)\n",
    "\n",
    "output = 1\n",
    "lag = const.LOOK_BACK\n",
    "\n",
    "reframed = data_tools.series_to_supervised(scaled, lag, output)\n",
    "# drop columns we don't want to predict\n",
    "index_drop = [-j-1 for j in range(data_multi.shape[1] - 1)]\n",
    "reframed.drop(reframed.columns[index_drop], axis=1, inplace=True)\n",
    "data_supervised = reframed.values\n",
    "print(\"# shape:\", reframed.shape)\n",
    "print(len(data_multi) == len(reframed) + lag)\n",
    "# print(reframed.head(3))\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(data_supervised) * const.TRAIN_SCALE)\n",
    "test_size = len(data_supervised) - train_size\n",
    "train_data, test_data = data_supervised[0:train_size,:], data_supervised[train_size:len(data_multi),:]\n",
    "print(len(train_data), len(test_data))\n",
    "print(len(data_supervised) == len(train_data) + len(test_data)) \n",
    "# print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainX: all, trainY: original price / col 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# shape: (1496, 120)\n",
      "# shape: (1496,)\n"
     ]
    }
   ],
   "source": [
    "# split into input and outputs\n",
    "train_X, train_Y = train_data[:, :-1], train_data[:, -1]\n",
    "test_X, test_Y = test_data[:, :-1], test_data[:, -1]\n",
    "print(\"# shape:\", train_X.shape)\n",
    "print(\"# shape:\", train_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# shuffle train set (include validation set)\n",
    "trainX_sparse = coo_matrix(train_X)  # sparse matrix\n",
    "train_X, trainX_sparse, train_Y = shuffle(train_X, trainX_sparse, train_Y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = lag\n",
    "# n_lstm_neurons = [8, 16, 32, 64, 128]\n",
    "n_lstm_neurons = [8]  # for once\n",
    "n_epoch = networks_factory.EPOCHS\n",
    "n_batch_size = networks_factory.BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1496, 30, 4) (1496,)\n",
      "(375, 30, 4) (375,)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], time_steps, train_X.shape[1]//time_steps))\n",
    "test_X = test_X.reshape((test_X.shape[0], time_steps, test_X.shape[1]//time_steps))\n",
    "print(train_X.shape, train_Y.shape)\n",
    "print(test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------n_lstm_neuron: 8--------------\n",
      "# Finished Training...\n",
      "Train RMSE: 1.3873, Test RMSE: 0.7405\n",
      "Train MAPE: 0.0970, Test MAPE: 0.0737\n",
      "Train Dstat: 0.8555, Test Dstat: 0.7807\n",
      "# All Done!\n"
     ]
    }
   ],
   "source": [
    "for i, n_lstm_neuron in enumerate(n_lstm_neurons):\n",
    "    \n",
    "    print(\"-----------n_lstm_neuron: %d--------------\" % n_lstm_neuron)\n",
    "    \n",
    "    s, model = networks_factory.create_lstm_model_dropout(lstm_neurons=n_lstm_neuron, hidden_layers=2, \n",
    "                                                          lenth=time_steps, dims=n_dims, n_out=1)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    history = model.fit(train_X, train_Y, epochs=10, batch_size=n_batch_size, validation_split=const.VALIDATION_SCALE,\n",
    "                    verbose=0, callbacks=[networks_factory.ES])  # callbacks=[networks_factory.ES]\n",
    "    print(\"# Finished Training...\")\n",
    "    \n",
    "    # make a prediction\n",
    "    train_predict = model.predict(train_X)\n",
    "    test_predict = model.predict(test_X)\n",
    "                                                    \n",
    "    # invert predictions\n",
    "    inv_trainP, inv_trainY = data_tools.inv_transform_multi(scaler, train_X, train_predict, train_Y)\n",
    "    inv_testP, inv_testY = data_tools.inv_transform_multi(scaler, test_X, test_predict, test_Y)\n",
    "\n",
    "    # calculate RMSE, MAPE, Dstat\n",
    "    train_rmse = sqrt(mean_squared_error(inv_trainP, inv_trainY))\n",
    "    test_rmse = sqrt(mean_squared_error(inv_testP, inv_testY))\n",
    "    print('Train RMSE: %.4f, Test RMSE: %.4f' % (train_rmse, test_rmse))\n",
    "    train_mape = data_metrics.MAPE(inv_trainP, inv_trainY)\n",
    "    test_mape = data_metrics.MAPE(inv_testP, inv_testY)\n",
    "    print('Train MAPE: %.4f, Test MAPE: %.4f' % (train_mape, test_mape))\n",
    "    train_ds = data_metrics.Dstat(inv_trainP, inv_trainY)\n",
    "    test_ds = data_metrics.Dstat(inv_testP, inv_testY)\n",
    "    print('Train Dstat: %.4f, Test Dstat: %.4f' % (train_ds, test_ds))\n",
    "    \n",
    "print(\"# All Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
